{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from paz.pipelines import MiniXceptionFER\n",
    "from paz.backend.image import show_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry: 0.1127\n",
      "disgust: 0.0130\n",
      "fear: 0.0243\n",
      "happy: 0.6239\n",
      "sad: 0.0582\n",
      "surprise: 0.0278\n",
      "neutral: 0.1401\n",
      "\n",
      "Predicted Emotion: HAPPY\n",
      "{'class_name': 'happy', 'scores': array([[0.11265942, 0.01297694, 0.02432909, 0.62394935, 0.05821391,\n",
      "        0.02779427, 0.14007702]], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "image = Image.open(\"./data/images/4/Happy.jpg\")\n",
    "image.show()\n",
    "numpy_image = asarray(image)\n",
    "\n",
    "classify = MiniXceptionFER()\n",
    "predictions = classify(numpy_image)\n",
    "\n",
    "scores = predictions[\"scores\"].flatten()\n",
    "\n",
    "for emotion, score in zip(emotions, scores):\n",
    "    print(f\"{emotion}: {score:.4f}\")\n",
    "\n",
    "print(f\"\\nPredicted Emotion: {predictions['class_name'].upper()}\")\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paz.applications import HaarCascadeFrontalFace, MiniXceptionFER\n",
    "import paz.processors as pr\n",
    "\n",
    "class EmotionDetector(pr.Processor):\n",
    "    def __init__(self):\n",
    "        super(EmotionDetector, self).__init__()\n",
    "        self.detect = HaarCascadeFrontalFace(draw=False)\n",
    "        self.crop = pr.CropBoxes2D()\n",
    "        self.classify = MiniXceptionFER()\n",
    "        self.draw = pr.DrawBoxes2D(self.classify.class_names)\n",
    "\n",
    "    def call(self, image):\n",
    "        boxes2D = self.detect(image)['boxes2D']\n",
    "        cropped_images = self.crop(image, boxes2D)\n",
    "        for cropped_image, box2D in zip(cropped_images, boxes2D):\n",
    "            box2D.class_name = self.classify(cropped_image)['class_name']\n",
    "        return self.draw(image, boxes2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect = EmotionDetector()\n",
    "\n",
    "predictions = detect(numpy_image.copy())\n",
    "\n",
    "Image.fromarray(predictions).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test accuracy for dataset,\n",
    "note that the datset is to our knowledge not scientifically pre-classified.\n",
    "\n",
    "We note that some emotions should be classified differently in our opinion.\n",
    "\n",
    "Create Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create script to take picture with camera"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
